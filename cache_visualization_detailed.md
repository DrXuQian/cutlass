# Swizzle 和 Raster Order 对缓存命中的详细可视化分析

## 1. 基础概念可视化

### 1.1 GEMM 分块结构
```
矩阵 C (输出) = 矩阵 A × 矩阵 B
[M×N]         [M×K]   [K×N]

将输出矩阵 C 分成多个 tiles，每个 CTA 负责一个 tile：

        N 维度
    ┌──────────────────┐
    │ T00│ T01│ T02│ T03│
M   │────┼────┼────┼────│
维  │ T10│ T11│ T12│ T13│
度  │────┼────┼────┼────│
    │ T20│ T21│ T22│ T23│
    │────┼────┼────┼────│
    │ T30│ T31│ T32│ T33│
    └──────────────────┘

每个 Tile (Tij) 需要：
- 从 A 读取第 i 行块
- 从 B 读取第 j 列块
```

## 2. Raster Order 可视化

### 2.1 AlongM (沿 M 维度优先遍历)

```
执行顺序（数字表示时间步）：

     列 0   列 1   列 2   列 3
    ┌─────┬─────┬─────┬─────┐
行0 │  0  │  4  │  8  │ 12  │  ← 先完成行0
    ├─────┼─────┼─────┼─────┤
行1 │  1  │  5  │  9  │ 13  │  ← 再完成行1
    ├─────┼─────┼─────┼─────┤
行2 │  2  │  6  │ 10  │ 14  │  ← 再完成行2
    ├─────┼─────┼─────┼─────┤
行3 │  3  │  7  │ 11  │ 15  │  ← 最后行3
    └─────┴─────┴─────┴─────┘
      ↑     ↑     ↑     ↑
    先列0  再列1  再列2  最后列3

数据访问时间线：
t0: CTA[0,0] → A[0,:], B[:,0] ←─┐
t1: CTA[1,0] → A[1,:], B[:,0] ←─┼─ B[:,0] 重用！
t2: CTA[2,0] → A[2,:], B[:,0] ←─┼─ B[:,0] 重用！
t3: CTA[3,0] → A[3,:], B[:,0] ←─┘  B[:,0] 重用！
t4: CTA[0,1] → A[0,:], B[:,1]      （B[:,0] 可能已被逐出）
```

### 2.2 AlongN (沿 N 维度优先遍历)

```
执行顺序：

     列 0   列 1   列 2   列 3
    ┌─────┬─────┬─────┬─────┐
行0 │  0  │  1  │  2  │  3  │ ← 先完成所有列
    ├─────┼─────┼─────┼─────┤
行1 │  4  │  5  │  6  │  7  │
    ├─────┼─────┼─────┼─────┤
行2 │  8  │  9  │ 10  │ 11  │
    ├─────┼─────┼─────┼─────┤
行3 │ 12  │ 13  │ 14  │ 15  │
    └─────┴─────┴─────┴─────┘
    先行0→─────────────────→

数据访问时间线：
t0: CTA[0,0] → A[0,:], B[:,0] ←─┐
t1: CTA[0,1] → A[0,:], B[:,1] ←─┼─ A[0,:] 重用！
t2: CTA[0,2] → A[0,:], B[:,2] ←─┼─ A[0,:] 重用！
t3: CTA[0,3] → A[0,:], B[:,3] ←─┘  A[0,:] 重用！
t4: CTA[1,0] → A[1,:], B[:,0]      （A[0,:] 可能已被逐出）
```

### 2.3 L2 缓存利用率对比

```
L2 缓存内容快照（假设缓存能容纳 4 个数据块）：

AlongM 模式下的缓存状态：
┌──────────────────────────────────────┐
│ 时刻 t0-t3：                         │
│ ┌─────────┬─────────┬───────┬──────┐│
│ │ B[:,0]  │ A[0,:]  │ A[1,:]│A[2,:]││
│ └─────────┴─────────┴───────┴──────┘│
│ B 数据驻留，被 4 个 CTA 重用         │
└──────────────────────────────────────┘

AlongN 模式下的缓存状态：
┌──────────────────────────────────────┐
│ 时刻 t0-t3：                         │
│ ┌─────────┬─────────┬───────┬──────┐│
│ │ A[0,:]  │ B[:,0]  │ B[:,1]│B[:,2]││
│ └─────────┴─────────┴───────┴──────┘│
│ A 数据驻留，被 4 个 CTA 重用         │
└──────────────────────────────────────┘
```

## 3. Swizzle 效果可视化

### 3.1 无 Swizzle (swizzle_size = 1)

```
16 个 CTA 在 4×4 网格上的执行顺序：

逻辑布局：                    实际调度顺序：
┌────┬────┬────┬────┐       时刻 t0: CTA[0,1,2,3]
│ 0  │ 1  │ 2  │ 3  │       时刻 t1: CTA[4,5,6,7]
├────┼────┼────┼────┤       时刻 t2: CTA[8,9,10,11]
│ 4  │ 5  │ 6  │ 7  │       时刻 t3: CTA[12,13,14,15]
├────┼────┼────┼────┤
│ 8  │ 9  │ 10 │ 11 │       问题：所有 SM 同时访问相邻区域！
├────┼────┼────┼────┤
│ 12 │ 13 │ 14 │ 15 │
└────┴────┴────┴────┘

内存访问热图（颜色深度表示访问密度）：
时刻 t0:
┌────────────────────┐
│████████████        │ ← 高度集中
│                    │
│                    │
│                    │
└────────────────────┘
```

### 3.2 Swizzle Size = 2

```
应用 swizzle 后的执行顺序：

原始顺序：                   Swizzle=2 后：
┌────┬────┬────┬────┐      ┌────┬────┬────┬────┐
│ 0  │ 1  │ 2  │ 3  │      │ 0  │ 2  │ 1  │ 3  │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 4  │ 5  │ 6  │ 7  │ →    │ 4  │ 6  │ 5  │ 7  │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 8  │ 9  │ 10 │ 11 │      │ 8  │ 10 │ 9  │ 11 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 12 │ 13 │ 14 │ 15 │      │ 12 │ 14 │ 13 │ 15 │
└────┴────┴────┴────┘      └────┴────┴────┴────┘

交织模式：偶数列和奇数列交换

内存访问热图：
时刻 t0（执行 CTA 0,2,4,6）：
┌────────────────────┐
│██  ██  ██  ██      │ ← 分散访问
│                    │
│                    │
│                    │
└────────────────────┘
```

### 3.3 Swizzle Size = 4

```
Swizzle=4 的执行顺序：

原始 4×4：                   Swizzle=4 后：
┌────┬────┬────┬────┐      ┌────┬────┬────┬────┐
│ 0  │ 1  │ 2  │ 3  │      │ 0  │ 4  │ 8  │ 12 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 4  │ 5  │ 6  │ 7  │ →    │ 1  │ 5  │ 9  │ 13 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 8  │ 9  │ 10 │ 11 │      │ 2  │ 6  │ 10 │ 14 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 12 │ 13 │ 14 │ 15 │      │ 3  │ 7  │ 11 │ 15 │
└────┴────┴────┴────┘      └────┴────┴────┴────┘

更大的交织跨度，访问更分散

内存访问热图：
时刻 t0（执行 CTA 0,4,8,12）：
┌────────────────────┐
│█   █   █   █       │ ← 高度分散
│                    │
│                    │
│                    │
└────────────────────┘
```

## 4. 组合效果：Raster Order + Swizzle

### 4.1 AlongM + 无 Swizzle

```
执行序列和缓存模式：

执行顺序（AlongM）：         L2 缓存竞争情况：
┌────┬────┬────┬────┐
│ 0  │ 4  │ 8  │ 12 │      时刻 t0-t3：
├────┼────┼────┼────┤      所有 CTA 访问 B[:,0]
│ 1  │ 5  │ 9  │ 13 │      ┌──────────────┐
├────┼────┼────┼────┤      │ B[:,0] 热点！ │
│ 2  │ 6  │ 10 │ 14 │      │ 缓存行竞争   │
├────┼────┼────┼────┤      └──────────────┘
│ 3  │ 7  │ 11 │ 15 │
└────┴────┴────┴────┘

缓存命中率：中等（B 重用好，但有竞争）
```

### 4.2 AlongM + Swizzle=4

```
执行序列优化后：

原始 AlongM：               + Swizzle=4：
┌────┬────┬────┬────┐      ┌────┬────┬────┬────┐
│ 0  │ 4  │ 8  │ 12 │      │ 0  │ 4  │ 8  │ 12 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 1  │ 5  │ 9  │ 13 │ →    │ 2  │ 6  │ 10 │ 14 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 2  │ 6  │ 10 │ 14 │      │ 1  │ 5  │ 9  │ 13 │
├────┼────┼────┼────┤      ├────┼────┼────┼────┤
│ 3  │ 7  │ 11 │ 15 │      │ 3  │ 7  │ 11 │ 15 │
└────┴────┴────┴────┘      └────┴────┴────┴────┘

L2 缓存访问模式：
时刻 t0：CTA[0,2] → B[:,0] 被两个分散的 CTA 访问
时刻 t1：CTA[4,6] → B[:,1] 缓存压力减轻
时刻 t2：CTA[8,10] → B[:,2]
时刻 t3：CTA[12,14] → B[:,3]

缓存命中率：高（B 重用 + 减少竞争）
```

## 5. 实际性能影响可视化

### 5.1 L2 缓存命中率对比

```
不同配置下的缓存命中率：

配置                    命中率图示
─────────────────────────────────────────
无 Swizzle + AlongM:   ████████░░░░░░░░  50%
                       (B重用好，但竞争严重)

Swizzle=2 + AlongM:    ████████████░░░░  75%
                       (B重用 + 中等分散)

Swizzle=4 + AlongM:    ███████████████░  90%
                       (B重用 + 高度分散)

无 Swizzle + AlongN:   ████████░░░░░░░░  50%
                       (A重用好，但竞争严重)

Swizzle=4 + AlongN:    ███████████████░  90%
                       (A重用 + 高度分散)
```

### 5.2 内存带宽利用率

```
时间线上的带宽利用（假设 4 个 SM）：

无 Swizzle：
SM0: ████████░░░░░░░░  (等待)
SM1: ████████░░░░░░░░  (等待)
SM2: ████████░░░░░░░░  (等待)
SM3: ████████░░░░░░░░  (等待)
     ↑
   所有 SM 同时访问相同缓存行

Swizzle=4：
SM0: ████░░████░░████  (交错)
SM1: ░░████░░████░░██  (交错)
SM2: ██░░████░░████░░  (交错)
SM3: ░░██░░████░░████  (交错)
     ↑
   SM 访问不同缓存行，减少冲突
```

## 6. 大规模矩阵的影响

### 6.1 矩阵规模对缓存的影响

```
小矩阵 (M=1024, N=1024)：
┌────────────────┐
│ 整个 B 矩阵    │ → 可能完全装入 L2
│ 能装入 L2      │   Swizzle 影响较小
└────────────────┘

大矩阵 (M=16384, N=16384)：
┌────────────────────────────┐
│ B 矩阵远超 L2 容量         │
│ ┌──────┐                   │
│ │L2容量│ ← 只能缓存一小部分 │
│ └──────┘                   │
│                            │ → Swizzle 至关重要
│                            │   避免缓存抖动
└────────────────────────────┘
```

### 6.2 Swizzle 对大矩阵的优化效果

```
64×64 CTA 网格，Swizzle=8 的效果：

无 Swizzle 时的问题：
时刻 t0：64 个 SM 全部访问前 64 个连续 tiles
┌─────────────────────────────┐
│████████████████             │ ← 极度集中！
│                             │   L2 缓存抖动严重
│                             │
└─────────────────────────────┘

Swizzle=8 后：
时刻 t0：64 个 SM 访问分散在整个矩阵的 tiles
┌─────────────────────────────┐
│█ █ █ █ █ █ █ █              │ ← 高度分散
│ █ █ █ █ █ █ █ █             │   L2 缓存利用充分
│█ █ █ █ █ █ █ █              │
└─────────────────────────────┘
```

## 7. 性能调优决策树

```
                 矩阵形状？
                    │
        ┌───────────┼───────────┐
        │           │           │
      M >> N      M ≈ N      N >> M
        │           │           │
    AlongM      Heuristic    AlongN
        │           │           │
        └───────────┼───────────┘
                    │
                矩阵大小？
                    │
        ┌───────────┼───────────┐
        │           │           │
       小         中等          大
   (<2048)    (2048-8192)    (>8192)
        │           │           │
   Swizzle=1-2  Swizzle=2-4  Swizzle=4-8
```

## 8. 实验数据可视化

### 8.1 性能热力图

```
性能 (TFLOPS) - M=8192, N=8192, K=4096：

        Swizzle=1  Swizzle=2  Swizzle=4  Swizzle=8
AlongM    120        145        165        170
AlongN    115        140        160        168
Heurist   125        150        162        169

颜色编码：
█ 170+ TFLOPS (最优)
▓ 150-170 TFLOPS
▒ 130-150 TFLOPS
░ <130 TFLOPS

热力图：
        S1    S2    S4    S8
AlongM  ░     ▒     ▓     █
AlongN  ░     ▒     ▓     █
Heurist ░     ▓     ▓     █
```

## 总结

1. **Raster Order** 决定了数据重用模式：
   - AlongM：优化 B 矩阵重用
   - AlongN：优化 A 矩阵重用

2. **Swizzle** 减少缓存竞争：
   - 通过分散 CTA 执行顺序
   - 减少同时访问相邻内存区域的 SM 数量

3. **组合使用** 获得最佳性能：
   - 选择合适的 Raster Order 基于矩阵形状
   - 使用 Swizzle 减少缓存行竞争
   - 大矩阵需要更大的 Swizzle Size

4. **L2 缓存** 是关键瓶颈：
   - Hopper H100 有 50MB L2 缓存
   - 合理的调度可以显著提升缓存利用率
   - 减少缓存抖动对大规模 GEMM 至关重要