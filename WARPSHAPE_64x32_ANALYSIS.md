# CUTLASS TensorOpMultiplicand 完整分析 - WarpShape 64x32

> M16N8K16 Instruction, kFactor=2, 2个k_groups

---

## 目录

1. [配置参数总览](#1-配置参数总览)
2. [Shared Memory 布局 (64x32)](#2-shared-memory-布局-64x32)
3. [Thread 映射表 (k_group 0)](#3-thread-映射表-k_group-0)
4. [Thread 访问模式可视化](#4-thread-访问模式可视化)
5. [K-Groups 和 operator++](#5-k-groups-和-operator)
6. [完整数据流](#6-完整数据流)
7. [关键公式](#7-关键公式)

---

## 1. 配置参数总览

```yaml
# Warp-level Tile
WarpShape:
  M: 64  # 64行
  K: 32  # 32列

# Tensor Core Instruction
InstructionShape:
  M: 16
  N: 8
  K: 16
  指令: mma.sync.aligned.m16n8k16.f16

# Layout
Layout: TensorOpMultiplicandCrosswise
kFactor: 2  # 2个partitions
kGroupsPerTile: 2  # K=32, InstructionK=16, 所以2个groups

# LDSM
LdsmShape:
  kCount: 4  # ldmatrix.x4
  kContiguous: 8
  kStrided: 8

LdsmIterations:
  kStrided: 1
  kContiguous: 4  # 需要4次ldsm调用

# Fragment
Fragment: Array<unsigned, 16>  # 1*4*4 = 16 registers

# SMEM
stride_: 32  # 每行32个元素
```

---

## 2. Shared Memory 布局 (64x32)

### 2.1 完整矩阵视图

```
64x32 矩阵 (只显示关键行):

           K 维度 →
     0  1  2  3  4 ...  15 16 17 18 ... 30 31
   ┌──────────────────────────────────────────┐
 0 │ (0,0) (0,1) ...           ... (0,30)(0,31)│
 1 │ (1,0) (1,1) ...           ... (1,30)(1,31)│
...│ ...                                   ... │
15 │(15,0)(15,1) ...           ...(15,30)(15,31)│
   ├──────────────────────────────────────────┤ InstructionShape 边界
16 │(16,0)(16,1) ...           ...(16,30)(16,31)│
...│ ...                                   ... │
31 │(31,0)(31,1) ...           ...(31,30)(31,31)│
   ├──────────────────────────────────────────┤
32 │(32,0)(32,1) ...           ...(32,30)(32,31)│
...│ ...                                   ... │
63 │(63,0)(63,1) ...           ...(63,30)(63,31)│
   └──────────────────────────────────────────┘
M维度 ↓
```

### 2.2 K维度的划分

```
K维度被划分为2个groups:

K-Group 0: K ∈ [0, 16)   (InstructionShape的K维度)
K-Group 1: K ∈ [16, 32)  (需要operator++访问)

    K:  0  1  2 ... 15 │ 16 17 18 ... 31
       └─ k_group 0 ──┘ └─ k_group 1 ──┘
```

### 2.3 Partition 划分 (kFactor=2)

```
每个k_group内部，K维度按奇偶分为2个partitions:

k_group 0 (K=0-15):
  Partition 0: K = 0,2,4,6,8,10,12,14  (偶数)
  Partition 1: K = 1,3,5,7,9,11,13,15  (奇数)

k_group 1 (K=16-31):
  Partition 0: K = 16,18,20,22,24,26,28,30  (偶数)
  Partition 1: K = 17,19,21,23,25,27,29,31  (奇数)
```

---

## 3. Thread 映射表 (k_group 0)

### 3.1 完整的32个Thread映射

```
┌────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┐
│ Thread │Partition │ Access   │ Access   │ Access_  │ Access_  │  Byte_   │  访问    │
│   ID   │   Idx    │ Cont Idx │ Stri Idx │Contiguous│ Strided  │ Offset   │ (M, K)   │
├────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤
│      0 │    0      │    0      │    0      │    0      │    0      │      0   │ ( 0, 0) │
│      1 │    1      │    0      │    0      │    8      │    0      │     16   │ ( 0, 8) │
│      2 │    0      │    1      │    1      │    1      │    1      │    258   │ ( 1, 1) │
│      3 │    1      │    1      │    1      │    9      │    1      │    274   │ ( 1, 9) │
│      4 │    0      │    2      │    2      │    2      │    2      │    516   │ ( 2, 2) │
│      5 │    1      │    2      │    2      │   10      │    2      │    532   │ ( 2,10) │
│      6 │    0      │    3      │    3      │    3      │    3      │    774   │ ( 3, 3) │
│      7 │    1      │    3      │    3      │   11      │    3      │    790   │ ( 3,11) │
│      8 │    0      │    0      │    4      │    0      │    4      │   1024   │ ( 4, 0) │
│      9 │    1      │    0      │    4      │    8      │    4      │   1040   │ ( 4, 8) │
│     10 │    0      │    1      │    5      │    1      │    5      │   1282   │ ( 5, 1) │
│     11 │    1      │    1      │    5      │    9      │    5      │   1298   │ ( 5, 9) │
│     12 │    0      │    2      │    6      │    2      │    6      │   1540   │ ( 6, 2) │
│     13 │    1      │    2      │    6      │   10      │    6      │   1556   │ ( 6,10) │
│     14 │    0      │    3      │    7      │    3      │    7      │   1798   │ ( 7, 3) │
│     15 │    1      │    3      │    7      │   11      │    7      │   1814   │ ( 7,11) │
│     16 │    0      │    0      │    8      │    0      │    8      │   2048   │ ( 8, 0) │
│     17 │    1      │    0      │    8      │    8      │    8      │   2064   │ ( 8, 8) │
│     18 │    0      │    1      │    9      │    1      │    9      │   2306   │ ( 9, 1) │
│     19 │    1      │    1      │    9      │    9      │    9      │   2322   │ ( 9, 9) │
│     20 │    0      │    2      │   10      │    2      │   10      │   2564   │ (10, 2) │
│     21 │    1      │    2      │   10      │   10      │   10      │   2580   │ (10,10) │
│     22 │    0      │    3      │   11      │    3      │   11      │   2822   │ (11, 3) │
│     23 │    1      │    3      │   11      │   11      │   11      │   2838   │ (11,11) │
│     24 │    0      │    0      │   12      │    0      │   12      │   3072   │ (12, 0) │
│     25 │    1      │    0      │   12      │    8      │   12      │   3088   │ (12, 8) │
│     26 │    0      │    1      │   13      │    1      │   13      │   3330   │ (13, 1) │
│     27 │    1      │    1      │   13      │    9      │   13      │   3346   │ (13, 9) │
│     28 │    0      │    2      │   14      │    2      │   14      │   3588   │ (14, 2) │
│     29 │    1      │    2      │   14      │   10      │   14      │   3604   │ (14,10) │
│     30 │    0      │    3      │   15      │    3      │   15      │   3846   │ (15, 3) │
│     31 │    1      │    3      │   15      │   11      │   15      │   3862   │ (15,11) │
└────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┘
```

**说明**:
- access_contiguous ∈ [0, 15]: 对应k_group 0中的K坐标
- access_strided ∈ [0, 15]: 对应M坐标的前16行
- 32个threads只覆盖64x32矩阵的一个16x16子块
- 需要WarpIterations (M方向4次) 来覆盖完整的64行

---

## 4. Thread 访问模式可视化

### 4.1 32个Threads在16x16子块上的分布

```
前16行, k_group 0 (K=0-15):

       K →  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
          ┌──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┐
  M  0 │ 0│ .│ .│ .│ .│ .│ .│ .│ 1│ .│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  1 │ .│ 2│ .│ .│ .│ .│ .│ .│ .│ 3│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  2 │ .│ .│ 4│ .│ .│ .│ .│ .│ .│ .│ 5│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  3 │ .│ .│ .│ 6│ .│ .│ .│ .│ .│ .│ .│ 7│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  4 │ 8│ .│ .│ .│ .│ .│ .│ .│ 9│ .│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  5 │ .│10│ .│ .│ .│ .│ .│ .│ .│11│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  6 │ .│ .│12│ .│ .│ .│ .│ .│ .│ .│13│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  7 │ .│ .│ .│14│ .│ .│ .│ .│ .│ .│ .│15│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  8 │16│ .│ .│ .│ .│ .│ .│ .│17│ .│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M  9 │ .│18│ .│ .│ .│ .│ .│ .│ .│19│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 10 │ .│ .│20│ .│ .│ .│ .│ .│ .│ .│21│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 11 │ .│ .│ .│22│ .│ .│ .│ .│ .│ .│ .│23│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 12 │24│ .│ .│ .│ .│ .│ .│ .│25│ .│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 13 │ .│26│ .│ .│ .│ .│ .│ .│ .│27│ .│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 14 │ .│ .│28│ .│ .│ .│ .│ .│ .│ .│29│ .│ .│ .│ .│ .│
       ├──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┼──┤
  M 15 │ .│ .│ .│30│ .│ .│ .│ .│ .│ .│ .│31│ .│ .│ .│ .│
       └──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┘
## = Thread ID
 . = 未被直接映射
```

### 4.2 完整64x32覆盖策略

```
M维度 (64行) 需要4次WarpIterations:
  Iteration 0: M ∈ [0, 16)   - 32 threads访问
  Iteration 1: M ∈ [16, 32)  - 32 threads访问
  Iteration 2: M ∈ [32, 48)  - 32 threads访问
  Iteration 3: M ∈ [48, 64)  - 32 threads访问

K维度 (32列) 需要2次k_group切换:
  k_group 0: K ∈ [0, 16)   - operator++ 前
  k_group 1: K ∈ [16, 32)  - operator++ 后
```

---

## 5. K-Groups 和 operator++

### 5.1 operator++ 的作用

```cpp
// 初始状态: k_group_idx_ = 0, 访问 K ∈ [0, 16)
load_with_byte_offset(frag, 0);  // 加载k_group 0

// 调用 operator++
iterator++;  // k_group_idx_ = 1

// 现在访问 K ∈ [16, 32)
load_with_byte_offset(frag, 0);  // 加载k_group 1
```

### 5.2 byte_offset 的XOR变化

对于kGroupsPerTile=2，XOR模式是: `^1`

```
XOR delta = 1 * LdsmShape::kContiguous * sizeof(half) * kElementsPerAccess
          = 1 * 8 * 2 * 8
          = 128 bytes

Thread 0 的变化:
  k_group 0: byte_offset = 0
  operator++
  k_group 1: byte_offset = 0 XOR 128 = 128
```

### 5.3 Thread 0-7 在两个k_groups的byte_offset对比

```
Thread │ k_group 0 │ k_group 1 │ XOR效果 │ 访问K范围变化
───────┼───────────┼───────────┼─────────┼──────────────
   0   │       0   │     128   │  ✓      │ K:0→16
   1   │      16   │     144   │  ✓      │ K:8→24
   2   │     258   │     386   │  ✓      │ K:1→17
   3   │     274   │     402   │  ✓      │ K:9→25
   4   │     516   │     644   │  ✓      │ K:2→18
   5   │     532   │     660   │  ✓      │ K:10→26
   6   │     774   │     902   │  ✓      │ K:3→19
   7   │     790   │     918   │  ✓      │ K:11→27
```

---

## 6. 完整数据流

### 6.1 时间线

```
初始化:
  构造函数 → 计算每个thread的初始byte_offset (k_group 0)

WarpIteration 0 (M=0-15):
  ├─ k_group 0: load → Fragment[0..15]
  ├─ operator++  (byte_offset ^= 128)
  ├─ k_group 1: load → Fragment[0..15]
  └─ MMA instruction (M16N8K16, 处理K=0-15 和 K=16-31)

WarpIteration 1 (M=16-31):
  └─ 重复上述过程，处理下一个16行

WarpIteration 2 (M=32-47):
WarpIteration 3 (M=48-63):
  完整覆盖64x32 warp tile
```

### 6.2 数据流图

```
┌─────────────────────────────────────┐
│ Shared Memory (64x32 Warp Tile)    │
│ TensorOpMultiplicandCrosswise       │
└──────────┬──────────────────────────┘
           │
           ├─→ k_group 0 (K=0-15)
           │   - 32 threads, 4x ldmatrix.x4
           │   - Fragment[0..15]
           │
           │   operator++ (XOR ^128)
           │
           └─→ k_group 1 (K=16-31)
               - 32 threads, 4x ldmatrix.x4
               - Fragment[0..15] (复用)
               │
               ↓
      ┌─────────────────────┐
      │  MMA m16n8k16       │
      │  Tensor Core        │
      └─────────────────────┘
```

---

## 7. 关键公式

### 7.1 Thread 到坐标的映射

```cpp
// 输入: lane_id (0-31), k_group_idx (0 or 1)

int lane_in_quad_pair = lane_id % 8;

// 中间索引
partition_idx = lane_id % 2;           // 0 or 1
access_cont_idx = lane_in_quad_pair / 2;  // 0-3
access_stri_idx = lane_id / 2;         // 0-15

// 最终坐标 (相对于k_group)
K = partition_idx * 8 + access_cont_idx;  // 0-15 (within k_group)
M = access_stri_idx;                      // 0-15 (within WarpIteration)

// 绝对K坐标
K_absolute = K + k_group_idx * 16;  // 0-31 (in full warp tile)
```

### 7.2 byte_offset 计算

```cpp
// 基础offset (k_group 0)
byte_offset = access_contiguous * 2 + access_strided * stride_ * kElementsPerAccess
            = K * 2 + M * 32 * 8
            = K * 2 + M * 256

// operator++ 后 (k_group 1)
byte_offset ^= (1 * 8 * 2 * 8)  // XOR 128
```

### 7.3 参数速查表

| 参数 | 值 | 说明 |
|------|----|----- |
| WarpShape | 64x32 | 一个warp处理的tile |
| InstructionShape | 16x8x16 | Tensor Core指令 |
| kFactor | 2 | Partition数量 |
| kGroupsPerTile | 2 | K维度分组数 |
| WarpIterations_M | 4 | M方向需要4次迭代 |
| LdsmShape::kCount | 4 | ldmatrix.x4 |
| Fragment size | 16 | 每thread 16个registers |
| stride_ | 32 | SMEM行宽 |

---

**文档结束**
